{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN METRICS",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYXjoFnINF0A",
        "outputId": "6e536b86-c6dd-4c17-af23-f5ebc84351d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgXTocHKSSg6",
        "outputId": "afac08ed-fa5d-4ac5-d223-9e7ca831b3b5"
      },
      "source": [
        "pip install numpy cython\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW5nlj8eSUg7",
        "outputId": "6004ab76-e499-40a7-ac23-07c00d8c96b4"
      },
      "source": [
        "!pip install POT\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: POT in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from POT) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from POT) (1.21.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HaCCNtG7uFq",
        "outputId": "b8110ca2-a448-4da3-892a-42add97371e5"
      },
      "source": [
        "pip install --upgrade numpy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeB0OfDih_MX"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import timeit\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import ot\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.models as models\n",
        "import pdb\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy.stats import entropy\n",
        "from numpy.linalg import norm\n",
        "from scipy import linalg\n",
        "\n",
        "\n",
        "def giveName(iter):  # 7 digit name.\n",
        "    ans = str(iter)\n",
        "    return ans.zfill(7)\n",
        "\n",
        "\n",
        "def make_dataset(dataset, dataroot, imageSize):\n",
        "    \"\"\"\n",
        "    :param dataset: must be in 'cifar10 | lsun | imagenet | folder | lfw | fake'\n",
        "    :return: pytorch dataset for DataLoader to utilize\n",
        "    \"\"\"\n",
        "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
        "        # folder dataset\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                       transforms.Resize(imageSize),\n",
        "                                       transforms.CenterCrop(imageSize),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                   ]))\n",
        "    elif dataset == 'lsun':\n",
        "        dataset = dset.LSUN(db_path=dataroot, classes=['bedroom_train'],\n",
        "                            transform=transforms.Compose([\n",
        "                                transforms.Resize(imageSize),\n",
        "                                transforms.CenterCrop(imageSize),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(\n",
        "                                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                            ]))\n",
        "    elif dataset == 'cifar10':\n",
        "        dataset = dset.CIFAR10(root=dataroot, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.Resize(imageSize),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(\n",
        "                                       (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                               ]))\n",
        "    elif dataset == 'celeba':\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                       transforms.CenterCrop(138),\n",
        "                                       transforms.Resize(imageSize),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                   ]))\n",
        "    else:\n",
        "        raise Exception('--dataset must be in cifar10 | lsun | imagenet | folder | lfw | fake')\n",
        "    assert dataset\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def sampleFake(netG, nz, sampleSize, batchSize, saveFolder):\n",
        "    print('sampling fake images ...')\n",
        "    saveFolder = saveFolder + '0/'\n",
        "\n",
        "    try:\n",
        "        os.makedirs(saveFolder)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "    noise = torch.FloatTensor(batchSize, nz, 1, 1).cuda()\n",
        "    iter = 0\n",
        "    for i in range(0, 1 + sampleSize // batchSize):\n",
        "        noise.data.normal_(0, 1)\n",
        "        fake = netG(noise)\n",
        "        for j in range(0, len(fake.data)):\n",
        "            if iter < sampleSize:\n",
        "                vutils.save_image(fake.data[j].mul(0.5).add(\n",
        "                    0.5), saveFolder + giveName(iter) + \".png\")\n",
        "            iter += 1\n",
        "            if iter >= sampleSize:\n",
        "                break\n",
        "\n",
        "\n",
        "def sampleTrue(dataset, imageSize, dataroot, sampleSize, batchSize, saveFolder, workers=4):\n",
        "    print('sampling real images ...')\n",
        "    saveFolder = saveFolder + '0/'\n",
        "\n",
        "    dataset = make_dataset(dataset, dataroot, imageSize)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, shuffle=True, batch_size=batchSize, num_workers=int(workers))\n",
        "\n",
        "    if not os.path.exists(saveFolder):\n",
        "        try:\n",
        "            os.makedirs(saveFolder)\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "    iter = 0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        img, _ = data\n",
        "        for j in range(0, len(img)):\n",
        "\n",
        "            vutils.save_image(img[j].mul(0.5).add(\n",
        "                0.5), saveFolder + giveName(iter) + \".png\")\n",
        "            iter += 1\n",
        "            if iter >= sampleSize:\n",
        "                break\n",
        "        if iter >= sampleSize:\n",
        "            break\n",
        "\n",
        "\n",
        "class ConvNetFeatureSaver(object):\n",
        "    def __init__(self, model='resnet34', workers=4, batchSize=64):\n",
        "        '''\n",
        "        model: inception_v3, vgg13, vgg16, vgg19, resnet18, resnet34,\n",
        "               resnet50, resnet101, or resnet152\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.batch_size = batchSize\n",
        "        self.workers = workers\n",
        "        if self.model.find('vgg') >= 0:\n",
        "            self.vgg = getattr(models, model)(pretrained=True).cuda().eval()\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                                     (0.229, 0.224, 0.225)),\n",
        "            ])\n",
        "        elif self.model.find('resnet') >= 0:\n",
        "            resnet = getattr(models, model)(pretrained=True)\n",
        "            resnet.cuda().eval()\n",
        "            resnet_feature = nn.Sequential(resnet.conv1, resnet.bn1,\n",
        "                                           resnet.relu,\n",
        "                                           resnet.maxpool, resnet.layer1,\n",
        "                                           resnet.layer2, resnet.layer3,\n",
        "                                           resnet.layer4).cuda().eval()\n",
        "            self.resnet = resnet\n",
        "            self.resnet_feature = resnet_feature\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                                     (0.229, 0.224, 0.225)),\n",
        "            ])\n",
        "        elif self.model == 'inception' or self.model == 'inception_v3':\n",
        "            inception = models.inception_v3(\n",
        "                pretrained=True, transform_input=False).cuda().eval()\n",
        "            inception_feature = nn.Sequential(inception.Conv2d_1a_3x3,\n",
        "                                              inception.Conv2d_2a_3x3,\n",
        "                                              inception.Conv2d_2b_3x3,\n",
        "                                              nn.MaxPool2d(3, 2),\n",
        "                                              inception.Conv2d_3b_1x1,\n",
        "                                              inception.Conv2d_4a_3x3,\n",
        "                                              nn.MaxPool2d(3, 2),\n",
        "                                              inception.Mixed_5b,\n",
        "                                              inception.Mixed_5c,\n",
        "                                              inception.Mixed_5d,\n",
        "                                              inception.Mixed_6a,\n",
        "                                              inception.Mixed_6b,\n",
        "                                              inception.Mixed_6c,\n",
        "                                              inception.Mixed_6d,\n",
        "                                              inception.Mixed_7a,\n",
        "                                              inception.Mixed_7b,\n",
        "                                              inception.Mixed_7c,\n",
        "                                              ).cuda().eval()\n",
        "            self.inception = inception\n",
        "            self.inception_feature = inception_feature\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(299),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ])\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def save(self, imgFolder, save2disk=False):\n",
        "        dataset = dset.ImageFolder(root=imgFolder, transform=self.trans)\n",
        "        dataloader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=self.batch_size, num_workers=self.workers)\n",
        "        print('extracting features...')\n",
        "        feature_pixl, feature_conv, feature_smax, feature_logit = [], [], [], []\n",
        "        for img, _ in tqdm(dataloader):\n",
        "            with torch.no_grad():\n",
        "                input = img.cuda()\n",
        "                if self.model == 'vgg' or self.model == 'vgg16':\n",
        "                    fconv = self.vgg.features(input).view(input.size(0), -1)\n",
        "                    flogit = self.vgg.classifier(fconv)\n",
        "                    # flogit = self.vgg.logitifier(fconv)\n",
        "                elif self.model.find('resnet') >= 0:\n",
        "                    fconv = self.resnet_feature(\n",
        "                        input).mean(3).mean(2).squeeze()\n",
        "                    flogit = self.resnet.fc(fconv)\n",
        "                elif self.model == 'inception' or self.model == 'inception_v3':\n",
        "                    fconv = self.inception_feature(\n",
        "                        input).mean(3).mean(2).squeeze()\n",
        "                    flogit = self.inception.fc(fconv)\n",
        "                else:\n",
        "                    raise NotImplementedError\n",
        "                fsmax = F.softmax(flogit)\n",
        "                feature_pixl.append(img)\n",
        "                feature_conv.append(fconv.data.cpu())\n",
        "                feature_logit.append(flogit.data.cpu())\n",
        "                feature_smax.append(fsmax.data.cpu())\n",
        "\n",
        "        feature_pixl = torch.cat(feature_pixl, 0).to('cpu')\n",
        "        feature_conv = torch.cat(feature_conv, 0).to('cpu')\n",
        "        feature_logit = torch.cat(feature_logit, 0).to('cpu')\n",
        "        feature_smax = torch.cat(feature_smax, 0).to('cpu')\n",
        "\n",
        "        if save2disk:\n",
        "            torch.save(feature_conv, os.path.join(\n",
        "                imgFolder, 'feature_pixl.pth'))\n",
        "            torch.save(feature_conv, os.path.join(\n",
        "                imgFolder, 'feature_conv.pth'))\n",
        "            torch.save(feature_logit, os.path.join(\n",
        "                imgFolder, 'feature_logit.pth'))\n",
        "            torch.save(feature_smax, os.path.join(\n",
        "                imgFolder, 'feature_smax.pth'))\n",
        "\n",
        "        return feature_pixl, feature_conv, feature_logit, feature_smax\n",
        "\n",
        "\n",
        "def distance(X, Y, sqrt):\n",
        "    nX = X.size(0)\n",
        "    nY = Y.size(0)\n",
        "    X = X.view(nX,-1)\n",
        "    X2 = (X*X).sum(1).resize_(nX,1)\n",
        "    Y = Y.view(nY,-1)\n",
        "    Y2 = (Y*Y).sum(1).resize_(nY,1)\n",
        "\n",
        "    M = torch.zeros(nX, nY)\n",
        "    M.copy_(X2.expand(nX, nY) + Y2.expand(nY, nX).transpose(0, 1) -\n",
        "            2 * torch.mm(X, Y.transpose(0, 1)))\n",
        "\n",
        "    del X, X2, Y, Y2\n",
        "\n",
        "    if sqrt:\n",
        "        M = ((M + M.abs()) / 2).sqrt()\n",
        "\n",
        "    return M\n",
        "\n",
        "\n",
        "def wasserstein(M, sqrt):\n",
        "    if sqrt:\n",
        "        M = M.abs().sqrt()\n",
        "    emd = ot.emd2([], [], M.numpy())\n",
        "\n",
        "    return emd\n",
        "\n",
        "\n",
        "class Score_knn:\n",
        "    acc = 0\n",
        "    acc_real = 0\n",
        "    acc_fake = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    tn = 0\n",
        "\n",
        "\n",
        "def knn(Mxx, Mxy, Myy, k, sqrt):\n",
        "    n0 = Mxx.size(0)\n",
        "    n1 = Myy.size(0)\n",
        "    label = torch.cat((torch.ones(n0), torch.zeros(n1)))\n",
        "    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat(\n",
        "        (Mxy.transpose(0, 1), Myy), 1)), 0)\n",
        "    if sqrt:\n",
        "        M = M.abs().sqrt()\n",
        "    INFINITY = float('inf')\n",
        "    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1))\n",
        "                ).topk(k, 0, False)\n",
        "\n",
        "    count = torch.zeros(n0 + n1)\n",
        "    for i in range(0, k):\n",
        "        count = count + label.index_select(0, idx[i])\n",
        "    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1)).float()\n",
        "\n",
        "    s = Score_knn()\n",
        "    s.tp = (pred * label).sum()\n",
        "    s.fp = (pred * (1 - label)).sum()\n",
        "    s.fn = ((1 - pred) * label).sum()\n",
        "    s.tn = ((1 - pred) * (1 - label)).sum()\n",
        "    s.precision = s.tp / (s.tp + s.fp + 1e-10)\n",
        "    s.recall = s.tp / (s.tp + s.fn + 1e-10)\n",
        "    s.acc_real = s.tp / (s.tp + s.fn)\n",
        "    s.acc_fake = s.tn / (s.tn + s.fp)\n",
        "    s.acc = torch.eq(label, pred).float().mean()\n",
        "    s.k = k\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def mmd(Mxx, Mxy, Myy, sigma):\n",
        "    scale = Mxx.mean()\n",
        "    Mxx = torch.exp(-Mxx / (scale * 2 * sigma * sigma))\n",
        "    Mxy = torch.exp(-Mxy / (scale * 2 * sigma * sigma))\n",
        "    Myy = torch.exp(-Myy / (scale * 2 * sigma * sigma))\n",
        "    mmd = math.sqrt(Mxx.mean() + Myy.mean() - 2 * Mxy.mean())\n",
        "\n",
        "    return mmd\n",
        "\n",
        "\n",
        "def entropy_score(X, Y, epsilons):\n",
        "    Mxy = distance(X, Y, False)\n",
        "    scores = []\n",
        "    for epsilon in epsilons:\n",
        "        scores.append(ent(Mxy.t(), epsilon))\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def ent(M, epsilon):\n",
        "    n0 = M.size(0)\n",
        "    n1 = M.size(1)\n",
        "    neighbors = M.lt(epsilon).float()\n",
        "    sums = neighbors.sum(0).repeat(n0, 1)\n",
        "    sums[sums.eq(0)] = 1\n",
        "    neighbors = neighbors.div(sums)\n",
        "    probs = neighbors.sum(1) / n1\n",
        "    rem = 1 - probs.sum()\n",
        "    if rem < 0:\n",
        "        rem = 0\n",
        "    probs = torch.cat((probs, rem*torch.ones(1)), 0)\n",
        "    e = {}\n",
        "    e['probs'] = probs\n",
        "    probs = probs[probs.gt(0)]\n",
        "    e['ent'] = -probs.mul(probs.log()).sum()\n",
        "\n",
        "    return e\n",
        "\n",
        "\n",
        "\n",
        "eps = 1e-20\n",
        "def inception_score(X):\n",
        "    kl = X * ((X+eps).log()-(X.mean(0)+eps).log().expand_as(X))\n",
        "    score = np.exp(kl.sum(1).mean())\n",
        "\n",
        "    return score\n",
        "\n",
        "def mode_score(X, Y):\n",
        "    kl1 = X * ((X+eps).log()-(X.mean(0)+eps).log().expand_as(X))\n",
        "    kl2 = X.mean(0) * ((X.mean(0)+eps).log()-(Y.mean(0)+eps).log())\n",
        "    score = np.exp(kl1.sum(1).mean() - kl2.sum())\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def fid(X, Y):\n",
        "    m = X.mean(0)\n",
        "    m_w = Y.mean(0)\n",
        "    X_np = X.numpy()\n",
        "    Y_np = Y.numpy()\n",
        "\n",
        "    C = np.cov(X_np.transpose())\n",
        "    C_w = np.cov(Y_np.transpose())\n",
        "    C_C_w_sqrt = linalg.sqrtm(C.dot(C_w), True).real\n",
        "\n",
        "    score = m.dot(m) + m_w.dot(m_w) - 2 * m_w.dot(m) + \\\n",
        "        np.trace(C + C_w - 2 * C_C_w_sqrt)\n",
        "    return np.sqrt(score)\n",
        "\n",
        "\n",
        "class Score:\n",
        "    emd = 0\n",
        "    mmd = 0\n",
        "    knn = None\n",
        "\n",
        "\n",
        "def compute_score(real, fake, k=1, sigma=1, sqrt=True):\n",
        "\n",
        "    Mxx = distance(real, real, False)\n",
        "    Mxy = distance(real, fake, False)\n",
        "    Myy = distance(fake, fake, False)\n",
        "\n",
        "    s = Score()\n",
        "    s.emd = wasserstein(Mxy, sqrt)\n",
        "    s.mmd = mmd(Mxx, Mxy, Myy, sigma)\n",
        "    s.knn = knn(Mxx, Mxy, Myy, k, sqrt)\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def compute_score_raw(dataset, imageSize, dataroot, sampleSize, batchSize,\n",
        "                      saveFolder_r, saveFolder_f, netG, nz,\n",
        "                      conv_model='resnet34', workers=4):\n",
        "\n",
        "    sampleTrue(dataset, imageSize, dataroot, sampleSize, batchSize,\n",
        "               saveFolder_r, workers=workers)\n",
        "    sampleFake(netG, nz, sampleSize, batchSize, saveFolder_f, )\n",
        "\n",
        "    convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,\n",
        "                                                batchSize=batchSize, workers=workers)\n",
        "    feature_r = convnet_feature_saver.save(saveFolder_r)\n",
        "    feature_f = convnet_feature_saver.save(saveFolder_f)\n",
        "\n",
        "    # 4 feature spaces and 7 scores + incep + modescore + fid\n",
        "    score = np.zeros(4 * 7 + 3)\n",
        "    for i in range(0, 4):\n",
        "        print('compute score in space: ' + str(i))\n",
        "        Mxx = distance(feature_r[i], feature_r[i], False)\n",
        "        Mxy = distance(feature_r[i], feature_f[i], False)\n",
        "        Myy = distance(feature_f[i], feature_f[i], False)\n",
        "\n",
        "        score[i * 7] = wasserstein(Mxy, True)\n",
        "        score[i * 7 + 1] = mmd(Mxx, Mxy, Myy, 1)\n",
        "        tmp = knn(Mxx, Mxy, Myy, 1, False)\n",
        "        score[(i * 7 + 2):(i * 7 + 7)] = \\\n",
        "            tmp.acc, tmp.acc_real, tmp.acc_fake, tmp.precision, tmp.recall\n",
        "\n",
        "    score[28] = inception_score(feature_f[3])\n",
        "    score[29] = mode_score(feature_r[3], feature_f[3])\n",
        "    score[30] = fid(feature_r[3], feature_f[3])\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2dCelc9fr_"
      },
      "source": [
        "    import torch\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne68M-jTic7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dddcf1f5-b829-485a-93fe-d600e64712e5"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "#import metric\n",
        "#from metric import make_dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "\n",
        "workers = 4\n",
        "batchSize = 32\n",
        "imageSize = 64\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "niter = 100\n",
        "lr = 0.002\n",
        "beta1 = 0.7\n",
        "ngpu = 1\n",
        "netG = ''\n",
        "netD = ''\n",
        "cuda = True\n",
        "outf = '/content/drive/My Drive/GAN/METRICS'\n",
        "dataset = 'folder'\n",
        "dataroot = '/content/drive/My Drive/LOP_DATASET/train/'\n",
        "sampleSize = 200\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    '''parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw | fake')\n",
        "    parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
        "    parser.add_argument('--workers', type=int, help='number of data loading workers', default=4)\n",
        "    parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
        "    parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n",
        "    parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
        "    parser.add_argument('--ngf', type=int, default=64)\n",
        "    parser.add_argument('--ndf', type=int, default=64)\n",
        "    parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
        "    parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
        "    parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
        "    parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
        "    parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
        "    parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
        "    parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
        "    parser.add_argument('--outf', default='results', help='folder to output images and model checkpoints')\n",
        "    parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
        "\n",
        "    ########################################################\n",
        "    #### For evaluation ####\n",
        "    parser.add_argument('--sampleSize', type=int, default=2000, help='number of samples for evaluation')\n",
        "    ########################################################\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "    print(opt)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(opt.outf)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "    if opt.manualSeed is None:\n",
        "        opt.manualSeed = random.randint(1, 10000)\n",
        "    print(\"Random Seed: \", opt.manualSeed)\n",
        "    random.seed(opt.manualSeed)\n",
        "    torch.manual_seed(opt.manualSeed)'''\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    #if torch.cuda.is_available() and not opt.cuda:\n",
        "     #   print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "    #########################\n",
        "    #### Dataset prepare ####\n",
        "    #########################\n",
        "    dataset = make_dataset(dataset='folder', dataroot='/content/drive/My Drive/LOP_DATASET/train/', imageSize = imageSize)\n",
        "    assert dataset\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32,shuffle=True, num_workers=int(1))\n",
        "\n",
        "    #########################\n",
        "    #### Models building ####\n",
        "    #########################\n",
        "    device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
        "    #ngpu = int(opt.ngpu)\n",
        "    #nz = int(opt.nz)\n",
        "   # ngf = int(opt.ngf)\n",
        "    #ndf = int(opt.ndf)\n",
        "    nc = 3\n",
        "\n",
        "    netG = Generator(ngpu).to(device)\n",
        "    netG.apply(weights_init)\n",
        "   # if netG != '':\n",
        "      #  netG.load_state_dict(torch.load(netG))\n",
        "    #print(netG)\n",
        "\n",
        "    netD = Discriminator(ngpu).to(device)\n",
        "    netD.apply(weights_init)\n",
        "   # if netD != '':\n",
        "     #   netD.load_state_dict(torch.load(netD))\n",
        "    #print(netD)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
        "    real_label = 1\n",
        "    fake_label = 0\n",
        "\n",
        "    # setup optimizer\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "    # [emd-mmd-knn(knn,real,fake,precision,recall)]*4 - IS - mode_score - FID\n",
        "    score_tr = np.zeros((niter, 4*7+3))\n",
        "\n",
        "    # compute initial score\n",
        "    s = compute_score_raw('folder', imageSize, dataroot, sampleSize, 16, outf+'/real/', outf+'/fake/',netG, nz, conv_model='inception_v3', workers=int(2))\n",
        "    score_tr[0] = s\n",
        "    np.save('%s/score_tr.npy' % (outf), score_tr)\n",
        "\n",
        "    #########################\n",
        "    #### Models training ####\n",
        "    #########################\n",
        "    for epoch in range(niter):\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "            # train with real\n",
        "            netD.zero_grad()\n",
        "            real_cpu = data[0].to(device)\n",
        "            batch_size = real_cpu.size(0)\n",
        "            label = torch.full((batch_size,), real_label, device=device)\n",
        "\n",
        "            output = netD(real_cpu)\n",
        "            label= label.to(device).float()\n",
        "            output= output.to(device).float()\n",
        "\n",
        "            #label = label.type(torch.LongTensor)\n",
        "            #output = output.type(torch.LongTensor)\n",
        "            errD_real = criterion(output, label)\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            # train with fake\n",
        "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "            fake = netG(noise)\n",
        "            label.fill_(fake_label)\n",
        "            output = netD(fake.detach())\n",
        "            errD_fake = criterion(output, label)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            errD = errD_real + errD_fake\n",
        "            optimizerD.step()\n",
        "\n",
        "            ############################\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost\n",
        "            output = netD(fake)\n",
        "            errG = criterion(output, label)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "            optimizerG.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "                      % (epoch, niter, i, len(dataloader),\n",
        "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            if i % 100 == 0:\n",
        "                vutils.save_image(real_cpu,\n",
        "                        '%s/real_samples.png' % outf,\n",
        "                        normalize=True)\n",
        "                fake = netG(fixed_noise)\n",
        "                vutils.save_image(fake.detach(),\n",
        "                        '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
        "                        normalize=True)\n",
        "\n",
        "        # do checkpointing\n",
        "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
        "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))\n",
        "\n",
        "        ################################################\n",
        "        #### metric scores computing (key function) ####\n",
        "        ################################################\n",
        "        s = compute_score_raw('folder', imageSize, dataroot, sampleSize, batchSize, outf+'/real/', outf+'/fake/',\\\n",
        "                                     netG, nz, conv_model='inception_v3', workers=int(workers))\n",
        "        score_tr[epoch] = s\n",
        "\n",
        "    # save final metric scores of all epoches\n",
        "    np.save('%s/score_tr_ep.npy' % outf, score_tr)\n",
        "    print('##### training completed :) #####')\n",
        "    print('### metric scores output is scored at %s/score_tr_ep.npy ###' % outf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sampling real images ...\n",
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:213: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 13/13 [00:02<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:02<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "compute score in space: 1\n",
            "compute score in space: 2\n",
            "compute score in space: 3\n",
            "[0/100][0/9] Loss_D: 1.6306 Loss_G: 45.0167 D(x): 0.7673 D(G(z)): 0.6897 / 0.0000\n",
            "sampling real images ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "compute score in space: 1\n",
            "compute score in space: 2\n",
            "compute score in space: 3\n",
            "[1/100][0/9] Loss_D: 100.0000 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "sampling real images ...\n",
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "compute score in space: 1\n",
            "compute score in space: 2\n",
            "compute score in space: 3\n",
            "[2/100][0/9] Loss_D: 100.0000 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "sampling real images ...\n",
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "compute score in space: 1\n",
            "compute score in space: 2\n",
            "compute score in space: 3\n",
            "[3/100][0/9] Loss_D: 100.0000 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "sampling real images ...\n",
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "compute score in space: 1\n",
            "compute score in space: 2\n",
            "compute score in space: 3\n",
            "[4/100][0/9] Loss_D: 100.0000 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "sampling real images ...\n",
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "compute score in space: 1\n",
            "compute score in space: 2\n",
            "compute score in space: 3\n",
            "[5/100][0/9] Loss_D: 100.0000 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "sampling real images ...\n",
            "sampling fake images ...\n",
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 3/7 [00:01<00:02,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-44ce03fd5ec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m#### metric scores computing (key function) ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_score_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'folder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/real/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/fake/'\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inception_v3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mscore_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1fee3990bdb9>\u001b[0m in \u001b[0;36mcompute_score_raw\u001b[0;34m(dataset, imageSize, dataroot, sampleSize, batchSize, saveFolder_r, saveFolder_f, netG, nz, conv_model, workers)\u001b[0m\n\u001b[1;32m    406\u001b[0m     convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,\n\u001b[1;32m    407\u001b[0m                                                 batchSize=batchSize, workers=workers)\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mfeature_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvnet_feature_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveFolder_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mfeature_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvnet_feature_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveFolder_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1fee3990bdb9>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, imgFolder, save2disk)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mfsmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mfeature_pixl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mfeature_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mfeature_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mfeature_smax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwbdChhBYrdw"
      },
      "source": [
        "new_num_arr = np.load('/content/drive/My Drive/METRICRESULTS/score_tr_ep.npy') # load\n",
        "print(new_num_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U88Zrv9ciZJz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}