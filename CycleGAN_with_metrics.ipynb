{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CycleGAN with metrics",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "175bfc9a17d8447d9e6dc010294581e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c8883daec7b473696802afd28dfb339",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f1e70f6943d4491961531f8a4b4cb85",
              "IPY_MODEL_57c9dab874274d9592fadb3c7a593a1f",
              "IPY_MODEL_f30705167937413683232dd01b8f0432"
            ]
          }
        },
        "4c8883daec7b473696802afd28dfb339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f1e70f6943d4491961531f8a4b4cb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_030a5b6636524a73bc3da10192cd8978",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6a6895f98c946bdbe2a3d8435aabee7"
          }
        },
        "57c9dab874274d9592fadb3c7a593a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1b1062e393e744eca4a4cf0d0ba44068",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108949747,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108949747,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35e103c52c5b4fda8cc8572d338cb166"
          }
        },
        "f30705167937413683232dd01b8f0432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_073d9abb0c784f158e762f3bfa7e17f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:00&lt;00:00, 124MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97b61f905bf8408994d3f13d0b06cfca"
          }
        },
        "030a5b6636524a73bc3da10192cd8978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6a6895f98c946bdbe2a3d8435aabee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b1062e393e744eca4a4cf0d0ba44068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35e103c52c5b4fda8cc8572d338cb166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "073d9abb0c784f158e762f3bfa7e17f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97b61f905bf8408994d3f13d0b06cfca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7lK69lcyqXM",
        "outputId": "0ad298a2-4402-44f2-e6c0-58495866b1d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAPlF_ebsmAK",
        "outputId": "00502762-70fd-4c1d-933f-1151edeef372"
      },
      "source": [
        "!git clone https://github.com/VyshnaviSK/Face2Mask-CycleGAN\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face2Mask-CycleGAN'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 78 (delta 21), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIR9CfJ3swtX"
      },
      "source": [
        "import os\n",
        "os.chdir('Face2Mask-CycleGAN/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr4D6gBHuDSu",
        "outputId": "17f6ea1d-e020-4b4d-ef6a-bd8b1a24c165"
      },
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.10.0+cu111)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (22.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.1-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=7ce71336fef2b14bb5082a1196acd952792ff54288d1ab0cb5b797c34f34a920\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5710 sha256=1d38664a7b32e13be167f61b22c4afe9d88cb82c30bd95e901644515b70ea4ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom, dominate\n",
            "Successfully installed dominate-2.6.0 jsonpatch-1.32 jsonpointer-2.1 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxkuLeU_294M"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCz4O7A6ugWb",
        "outputId": "4fd1f05d-424f-43f1-97ab-f10fa06c8b0f"
      },
      "source": [
        "!python train.py --dataroot '/content/drive/My Drive/CGAN_LOP' --name LOP --model cycle_gan --batch_size 4 --checkpoints_dir '/content/drive/My Drive/CGAN_LOP/train_chkpts' --continue_train --epoch_count 116\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 4                             \t[default: 1]\n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: /content/drive/My Drive/CGAN_LOP/train_chkpts\t[default: ./checkpoints]\n",
            "           continue_train: True                          \t[default: False]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/My Drive/CGAN_LOP\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 116                           \t[default: 1]\n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: LOP                           \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "The number of training images = 173\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "loading the model from /content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/latest_net_G_A.pth\n",
            "loading the model from /content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/latest_net_G_B.pth\n",
            "loading the model from /content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/latest_net_D_A.pth\n",
            "loading the model from /content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/latest_net_D_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fafeadea910>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fafeadea910>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fafeadea910>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory /content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/web...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "(epoch: 116, iters: 100, time: 1.229, data: 3.314) D_A: 0.298 G_A: 0.298 cycle_A: 0.278 idt_A: 0.115 D_B: 0.243 G_B: 0.264 cycle_B: 0.278 idt_B: 0.089 \n",
            "End of epoch 116 / 200 \t Time Taken: 208 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 24, time: 1.226, data: 0.003) D_A: 0.216 G_A: 0.242 cycle_A: 0.239 idt_A: 0.122 D_B: 0.336 G_B: 0.538 cycle_B: 0.295 idt_B: 0.087 \n",
            "(epoch: 117, iters: 124, time: 1.225, data: 0.002) D_A: 0.258 G_A: 0.305 cycle_A: 0.269 idt_A: 0.127 D_B: 0.246 G_B: 0.213 cycle_B: 0.223 idt_B: 0.132 \n",
            "End of epoch 117 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 48, time: 1.597, data: 0.003) D_A: 0.273 G_A: 0.305 cycle_A: 0.267 idt_A: 0.111 D_B: 0.237 G_B: 0.246 cycle_B: 0.265 idt_B: 0.126 \n",
            "(epoch: 118, iters: 148, time: 1.230, data: 0.006) D_A: 0.234 G_A: 0.340 cycle_A: 0.214 idt_A: 0.144 D_B: 0.254 G_B: 0.281 cycle_B: 0.287 idt_B: 0.083 \n",
            "End of epoch 118 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 72, time: 1.229, data: 0.003) D_A: 0.265 G_A: 0.288 cycle_A: 0.503 idt_A: 0.216 D_B: 0.400 G_B: 0.346 cycle_B: 0.543 idt_B: 0.167 \n",
            "(epoch: 119, iters: 172, time: 1.228, data: 0.003) D_A: 0.250 G_A: 0.303 cycle_A: 0.341 idt_A: 0.142 D_B: 0.252 G_B: 0.240 cycle_B: 0.375 idt_B: 0.131 \n",
            "End of epoch 119 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 96, time: 1.588, data: 0.003) D_A: 0.260 G_A: 0.258 cycle_A: 0.382 idt_A: 0.071 D_B: 0.264 G_B: 0.292 cycle_B: 0.257 idt_B: 0.148 \n",
            "saving the model at the end of epoch 120, iters 880\n",
            "End of epoch 120 / 200 \t Time Taken: 207 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 20, time: 1.230, data: 0.004) D_A: 0.242 G_A: 0.281 cycle_A: 0.390 idt_A: 0.126 D_B: 0.279 G_B: 0.225 cycle_B: 0.340 idt_B: 0.167 \n",
            "(epoch: 121, iters: 120, time: 1.231, data: 0.006) D_A: 0.242 G_A: 0.268 cycle_A: 0.321 idt_A: 0.075 D_B: 0.272 G_B: 0.268 cycle_B: 0.210 idt_B: 0.133 \n",
            "End of epoch 121 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 44, time: 1.228, data: 0.005) D_A: 0.305 G_A: 0.304 cycle_A: 0.310 idt_A: 0.095 D_B: 0.220 G_B: 0.258 cycle_B: 0.255 idt_B: 0.143 \n",
            "(epoch: 122, iters: 144, time: 1.585, data: 0.003) D_A: 0.251 G_A: 0.296 cycle_A: 0.254 idt_A: 0.078 D_B: 0.251 G_B: 0.316 cycle_B: 0.206 idt_B: 0.137 \n",
            "End of epoch 122 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 68, time: 1.230, data: 0.003) D_A: 0.265 G_A: 0.216 cycle_A: 0.343 idt_A: 0.085 D_B: 0.266 G_B: 0.306 cycle_B: 0.244 idt_B: 0.133 \n",
            "(epoch: 123, iters: 168, time: 1.230, data: 0.003) D_A: 0.251 G_A: 0.321 cycle_A: 0.414 idt_A: 0.119 D_B: 0.265 G_B: 0.322 cycle_B: 0.280 idt_B: 0.220 \n",
            "End of epoch 123 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 92, time: 1.229, data: 0.003) D_A: 0.292 G_A: 0.299 cycle_A: 0.430 idt_A: 0.117 D_B: 0.224 G_B: 0.216 cycle_B: 0.319 idt_B: 0.181 \n",
            "End of epoch 124 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 16, time: 1.591, data: 0.004) D_A: 0.252 G_A: 0.234 cycle_A: 0.235 idt_A: 0.078 D_B: 0.255 G_B: 0.232 cycle_B: 0.220 idt_B: 0.102 \n",
            "(epoch: 125, iters: 116, time: 1.228, data: 0.009) D_A: 0.283 G_A: 0.229 cycle_A: 0.290 idt_A: 0.105 D_B: 0.242 G_B: 0.242 cycle_B: 0.235 idt_B: 0.115 \n",
            "saving the model at the end of epoch 125, iters 1760\n",
            "End of epoch 125 / 200 \t Time Taken: 206 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 40, time: 1.218, data: 0.003) D_A: 0.254 G_A: 0.302 cycle_A: 0.317 idt_A: 0.104 D_B: 0.371 G_B: 0.659 cycle_B: 0.214 idt_B: 0.151 \n",
            "(epoch: 126, iters: 140, time: 1.221, data: 0.003) D_A: 0.235 G_A: 0.270 cycle_A: 0.243 idt_A: 0.137 D_B: 0.260 G_B: 0.371 cycle_B: 0.362 idt_B: 0.127 \n",
            "End of epoch 126 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 64, time: 1.579, data: 0.003) D_A: 0.260 G_A: 0.246 cycle_A: 0.378 idt_A: 0.073 D_B: 0.251 G_B: 0.249 cycle_B: 0.208 idt_B: 0.179 \n",
            "(epoch: 127, iters: 164, time: 1.220, data: 0.004) D_A: 0.255 G_A: 0.302 cycle_A: 0.258 idt_A: 0.108 D_B: 0.250 G_B: 0.237 cycle_B: 0.199 idt_B: 0.100 \n",
            "End of epoch 127 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 88, time: 1.222, data: 0.003) D_A: 0.334 G_A: 0.246 cycle_A: 0.230 idt_A: 0.070 D_B: 0.288 G_B: 0.122 cycle_B: 0.163 idt_B: 0.114 \n",
            "End of epoch 128 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 12, time: 1.218, data: 0.003) D_A: 0.250 G_A: 0.285 cycle_A: 0.318 idt_A: 0.116 D_B: 0.262 G_B: 0.241 cycle_B: 0.212 idt_B: 0.169 \n",
            "(epoch: 129, iters: 112, time: 1.604, data: 0.002) D_A: 0.251 G_A: 0.170 cycle_A: 0.282 idt_A: 0.164 D_B: 0.240 G_B: 0.295 cycle_B: 0.319 idt_B: 0.122 \n",
            "End of epoch 129 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 36, time: 1.219, data: 0.003) D_A: 0.301 G_A: 0.326 cycle_A: 0.219 idt_A: 0.172 D_B: 0.231 G_B: 0.287 cycle_B: 0.326 idt_B: 0.093 \n",
            "(epoch: 130, iters: 136, time: 1.218, data: 0.003) D_A: 0.247 G_A: 0.279 cycle_A: 0.298 idt_A: 0.071 D_B: 0.219 G_B: 0.335 cycle_B: 0.195 idt_B: 0.127 \n",
            "saving the model at the end of epoch 130, iters 2640\n",
            "End of epoch 130 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 60, time: 1.217, data: 0.003) D_A: 0.251 G_A: 0.264 cycle_A: 0.156 idt_A: 0.104 D_B: 0.228 G_B: 0.306 cycle_B: 0.238 idt_B: 0.066 \n",
            "(epoch: 131, iters: 160, time: 1.594, data: 0.003) D_A: 0.278 G_A: 0.193 cycle_A: 0.319 idt_A: 0.105 D_B: 0.251 G_B: 0.263 cycle_B: 0.254 idt_B: 0.145 \n",
            "End of epoch 131 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 84, time: 1.217, data: 0.005) D_A: 0.273 G_A: 0.301 cycle_A: 0.219 idt_A: 0.139 D_B: 0.276 G_B: 0.201 cycle_B: 0.238 idt_B: 0.091 \n",
            "End of epoch 132 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 8, time: 1.217, data: 0.003) D_A: 0.253 G_A: 0.329 cycle_A: 0.146 idt_A: 0.089 D_B: 0.246 G_B: 0.227 cycle_B: 0.216 idt_B: 0.061 \n",
            "(epoch: 133, iters: 108, time: 1.218, data: 0.001) D_A: 0.238 G_A: 0.269 cycle_A: 0.359 idt_A: 0.143 D_B: 0.235 G_B: 0.268 cycle_B: 0.314 idt_B: 0.160 \n",
            "End of epoch 133 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 32, time: 1.612, data: 0.003) D_A: 0.256 G_A: 0.236 cycle_A: 0.346 idt_A: 0.066 D_B: 0.219 G_B: 0.288 cycle_B: 0.146 idt_B: 0.115 \n",
            "(epoch: 134, iters: 132, time: 1.218, data: 0.004) D_A: 0.225 G_A: 0.371 cycle_A: 0.181 idt_A: 0.082 D_B: 0.225 G_B: 0.260 cycle_B: 0.185 idt_B: 0.083 \n",
            "End of epoch 134 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 56, time: 1.218, data: 0.004) D_A: 0.212 G_A: 0.303 cycle_A: 0.260 idt_A: 0.250 D_B: 0.229 G_B: 0.312 cycle_B: 0.431 idt_B: 0.122 \n",
            "(epoch: 135, iters: 156, time: 1.219, data: 0.003) D_A: 0.196 G_A: 0.282 cycle_A: 0.202 idt_A: 0.176 D_B: 0.222 G_B: 0.299 cycle_B: 0.339 idt_B: 0.087 \n",
            "saving the model at the end of epoch 135, iters 3520\n",
            "End of epoch 135 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 80, time: 1.591, data: 0.003) D_A: 0.244 G_A: 0.330 cycle_A: 0.302 idt_A: 0.074 D_B: 0.262 G_B: 0.250 cycle_B: 0.178 idt_B: 0.139 \n",
            "End of epoch 136 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 4, time: 1.154, data: 0.003) D_A: 0.257 G_A: 0.250 cycle_A: 0.592 idt_A: 0.124 D_B: 0.166 G_B: 0.308 cycle_B: 0.331 idt_B: 0.310 \n",
            "(epoch: 137, iters: 104, time: 1.220, data: 0.001) D_A: 0.280 G_A: 0.162 cycle_A: 0.413 idt_A: 0.122 D_B: 0.245 G_B: 0.307 cycle_B: 0.339 idt_B: 0.135 \n",
            "End of epoch 137 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 28, time: 1.218, data: 0.006) D_A: 0.259 G_A: 0.277 cycle_A: 0.264 idt_A: 0.114 D_B: 0.268 G_B: 0.212 cycle_B: 0.143 idt_B: 0.133 \n",
            "(epoch: 138, iters: 128, time: 1.608, data: 0.002) D_A: 0.230 G_A: 0.235 cycle_A: 0.275 idt_A: 0.181 D_B: 0.251 G_B: 0.284 cycle_B: 0.308 idt_B: 0.112 \n",
            "End of epoch 138 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 52, time: 1.216, data: 0.004) D_A: 0.238 G_A: 0.200 cycle_A: 0.269 idt_A: 0.091 D_B: 0.252 G_B: 0.295 cycle_B: 0.208 idt_B: 0.101 \n",
            "(epoch: 139, iters: 152, time: 1.220, data: 0.003) D_A: 0.235 G_A: 0.277 cycle_A: 0.174 idt_A: 0.073 D_B: 0.250 G_B: 0.242 cycle_B: 0.152 idt_B: 0.074 \n",
            "End of epoch 139 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 76, time: 1.214, data: 0.003) D_A: 0.239 G_A: 0.331 cycle_A: 0.272 idt_A: 0.139 D_B: 0.258 G_B: 0.280 cycle_B: 0.393 idt_B: 0.112 \n",
            "(epoch: 140, iters: 176, time: 0.743, data: 0.003) D_A: 0.260 G_A: 0.247 cycle_A: 0.231 idt_A: 0.048 D_B: 0.264 G_B: 0.274 cycle_B: 0.226 idt_B: 0.092 \n",
            "saving the model at the end of epoch 140, iters 4400\n",
            "End of epoch 140 / 200 \t Time Taken: 205 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 1.220, data: 0.657) D_A: 0.264 G_A: 0.276 cycle_A: 0.232 idt_A: 0.093 D_B: 0.244 G_B: 0.272 cycle_B: 0.231 idt_B: 0.119 \n",
            "End of epoch 141 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 24, time: 1.219, data: 0.004) D_A: 0.275 G_A: 0.226 cycle_A: 0.258 idt_A: 0.073 D_B: 0.291 G_B: 0.371 cycle_B: 0.203 idt_B: 0.126 \n",
            "(epoch: 142, iters: 124, time: 1.217, data: 0.001) D_A: 0.271 G_A: 0.207 cycle_A: 0.222 idt_A: 0.105 D_B: 0.257 G_B: 0.296 cycle_B: 0.222 idt_B: 0.114 \n",
            "End of epoch 142 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 48, time: 1.591, data: 0.003) D_A: 0.263 G_A: 0.226 cycle_A: 0.227 idt_A: 0.144 D_B: 0.213 G_B: 0.255 cycle_B: 0.264 idt_B: 0.081 \n",
            "(epoch: 143, iters: 148, time: 1.226, data: 0.005) D_A: 0.240 G_A: 0.176 cycle_A: 0.206 idt_A: 0.109 D_B: 0.252 G_B: 0.238 cycle_B: 0.236 idt_B: 0.090 \n",
            "End of epoch 143 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 72, time: 1.218, data: 0.002) D_A: 0.254 G_A: 0.281 cycle_A: 0.227 idt_A: 0.104 D_B: 0.248 G_B: 0.247 cycle_B: 0.243 idt_B: 0.074 \n",
            "saving the latest model (epoch 144, total_iters 5000)\n",
            "(epoch: 144, iters: 172, time: 1.222, data: 0.003) D_A: 0.243 G_A: 0.235 cycle_A: 0.215 idt_A: 0.116 D_B: 0.245 G_B: 0.308 cycle_B: 0.342 idt_B: 0.088 \n",
            "End of epoch 144 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 96, time: 1.595, data: 0.003) D_A: 0.258 G_A: 0.236 cycle_A: 0.158 idt_A: 0.087 D_B: 0.259 G_B: 0.307 cycle_B: 0.174 idt_B: 0.075 \n",
            "saving the model at the end of epoch 145, iters 5280\n",
            "End of epoch 145 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 20, time: 1.219, data: 0.003) D_A: 0.231 G_A: 0.260 cycle_A: 0.237 idt_A: 0.130 D_B: 0.268 G_B: 0.229 cycle_B: 0.239 idt_B: 0.117 \n",
            "(epoch: 146, iters: 120, time: 1.219, data: 0.006) D_A: 0.246 G_A: 0.246 cycle_A: 0.241 idt_A: 0.086 D_B: 0.239 G_B: 0.276 cycle_B: 0.218 idt_B: 0.104 \n",
            "End of epoch 146 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 44, time: 1.220, data: 0.003) D_A: 0.253 G_A: 0.316 cycle_A: 0.188 idt_A: 0.070 D_B: 0.248 G_B: 0.241 cycle_B: 0.157 idt_B: 0.066 \n",
            "(epoch: 147, iters: 144, time: 1.605, data: 0.003) D_A: 0.247 G_A: 0.283 cycle_A: 0.329 idt_A: 0.100 D_B: 0.275 G_B: 0.223 cycle_B: 0.200 idt_B: 0.134 \n",
            "End of epoch 147 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 68, time: 1.221, data: 0.003) D_A: 0.206 G_A: 0.246 cycle_A: 0.250 idt_A: 0.143 D_B: 0.243 G_B: 0.360 cycle_B: 0.289 idt_B: 0.151 \n",
            "(epoch: 148, iters: 168, time: 1.220, data: 0.003) D_A: 0.244 G_A: 0.204 cycle_A: 0.218 idt_A: 0.110 D_B: 0.225 G_B: 0.327 cycle_B: 0.220 idt_B: 0.100 \n",
            "End of epoch 148 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 92, time: 1.220, data: 0.003) D_A: 0.247 G_A: 0.327 cycle_A: 0.175 idt_A: 0.099 D_B: 0.248 G_B: 0.283 cycle_B: 0.231 idt_B: 0.076 \n",
            "End of epoch 149 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 16, time: 1.603, data: 0.003) D_A: 0.263 G_A: 0.224 cycle_A: 0.265 idt_A: 0.121 D_B: 0.261 G_B: 0.236 cycle_B: 0.289 idt_B: 0.110 \n",
            "(epoch: 150, iters: 116, time: 1.225, data: 0.008) D_A: 0.248 G_A: 0.253 cycle_A: 0.441 idt_A: 0.091 D_B: 0.290 G_B: 0.224 cycle_B: 0.262 idt_B: 0.170 \n",
            "saving the model at the end of epoch 150, iters 6160\n",
            "End of epoch 150 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 40, time: 1.222, data: 0.004) D_A: 0.271 G_A: 0.201 cycle_A: 0.316 idt_A: 0.079 D_B: 0.280 G_B: 0.227 cycle_B: 0.174 idt_B: 0.115 \n",
            "(epoch: 151, iters: 140, time: 1.224, data: 0.003) D_A: 0.208 G_A: 0.217 cycle_A: 0.180 idt_A: 0.095 D_B: 0.257 G_B: 0.294 cycle_B: 0.226 idt_B: 0.072 \n",
            "End of epoch 151 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 64, time: 1.606, data: 0.003) D_A: 0.236 G_A: 0.248 cycle_A: 0.398 idt_A: 0.083 D_B: 0.241 G_B: 0.352 cycle_B: 0.237 idt_B: 0.157 \n",
            "(epoch: 152, iters: 164, time: 1.225, data: 0.005) D_A: 0.226 G_A: 0.317 cycle_A: 0.160 idt_A: 0.092 D_B: 0.225 G_B: 0.339 cycle_B: 0.213 idt_B: 0.073 \n",
            "End of epoch 152 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 88, time: 1.223, data: 0.003) D_A: 0.281 G_A: 0.218 cycle_A: 0.312 idt_A: 0.091 D_B: 0.242 G_B: 0.226 cycle_B: 0.207 idt_B: 0.152 \n",
            "End of epoch 153 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 12, time: 1.220, data: 0.003) D_A: 0.253 G_A: 0.352 cycle_A: 0.199 idt_A: 0.088 D_B: 0.252 G_B: 0.176 cycle_B: 0.267 idt_B: 0.091 \n",
            "(epoch: 154, iters: 112, time: 1.627, data: 0.002) D_A: 0.237 G_A: 0.203 cycle_A: 0.270 idt_A: 0.151 D_B: 0.242 G_B: 0.319 cycle_B: 0.316 idt_B: 0.130 \n",
            "End of epoch 154 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 36, time: 1.223, data: 0.004) D_A: 0.238 G_A: 0.235 cycle_A: 0.173 idt_A: 0.106 D_B: 0.267 G_B: 0.223 cycle_B: 0.223 idt_B: 0.083 \n",
            "(epoch: 155, iters: 136, time: 1.217, data: 0.002) D_A: 0.266 G_A: 0.276 cycle_A: 0.193 idt_A: 0.112 D_B: 0.215 G_B: 0.401 cycle_B: 0.234 idt_B: 0.080 \n",
            "saving the model at the end of epoch 155, iters 7040\n",
            "End of epoch 155 / 200 \t Time Taken: 204 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 60, time: 1.222, data: 0.003) D_A: 0.230 G_A: 0.337 cycle_A: 0.226 idt_A: 0.102 D_B: 0.222 G_B: 0.330 cycle_B: 0.228 idt_B: 0.125 \n",
            "(epoch: 156, iters: 160, time: 1.609, data: 0.005) D_A: 0.234 G_A: 0.333 cycle_A: 0.340 idt_A: 0.102 D_B: 0.242 G_B: 0.327 cycle_B: 0.166 idt_B: 0.146 \n",
            "End of epoch 156 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 84, time: 1.221, data: 0.002) D_A: 0.255 G_A: 0.335 cycle_A: 0.217 idt_A: 0.073 D_B: 0.232 G_B: 0.256 cycle_B: 0.155 idt_B: 0.110 \n",
            "End of epoch 157 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 8, time: 1.220, data: 0.003) D_A: 0.219 G_A: 0.324 cycle_A: 0.151 idt_A: 0.093 D_B: 0.228 G_B: 0.260 cycle_B: 0.212 idt_B: 0.071 \n",
            "(epoch: 158, iters: 108, time: 1.225, data: 0.004) D_A: 0.268 G_A: 0.235 cycle_A: 0.212 idt_A: 0.064 D_B: 0.225 G_B: 0.281 cycle_B: 0.151 idt_B: 0.084 \n",
            "End of epoch 158 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 32, time: 1.605, data: 0.003) D_A: 0.252 G_A: 0.269 cycle_A: 0.281 idt_A: 0.064 D_B: 0.240 G_B: 0.288 cycle_B: 0.154 idt_B: 0.143 \n",
            "(epoch: 159, iters: 132, time: 1.224, data: 0.003) D_A: 0.233 G_A: 0.314 cycle_A: 0.313 idt_A: 0.102 D_B: 0.208 G_B: 0.261 cycle_B: 0.205 idt_B: 0.183 \n",
            "End of epoch 159 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 56, time: 1.217, data: 0.003) D_A: 0.237 G_A: 0.296 cycle_A: 0.150 idt_A: 0.070 D_B: 0.189 G_B: 0.290 cycle_B: 0.147 idt_B: 0.086 \n",
            "(epoch: 160, iters: 156, time: 1.220, data: 0.003) D_A: 0.254 G_A: 0.289 cycle_A: 0.165 idt_A: 0.078 D_B: 0.242 G_B: 0.292 cycle_B: 0.201 idt_B: 0.084 \n",
            "saving the model at the end of epoch 160, iters 7920\n",
            "End of epoch 160 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 80, time: 1.606, data: 0.003) D_A: 0.254 G_A: 0.219 cycle_A: 0.157 idt_A: 0.066 D_B: 0.272 G_B: 0.261 cycle_B: 0.152 idt_B: 0.081 \n",
            "End of epoch 161 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 4, time: 1.153, data: 0.003) D_A: 0.241 G_A: 0.385 cycle_A: 0.180 idt_A: 0.119 D_B: 0.225 G_B: 0.178 cycle_B: 0.290 idt_B: 0.080 \n",
            "(epoch: 162, iters: 104, time: 1.216, data: 0.001) D_A: 0.228 G_A: 0.251 cycle_A: 0.319 idt_A: 0.069 D_B: 0.229 G_B: 0.255 cycle_B: 0.169 idt_B: 0.128 \n",
            "End of epoch 162 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 28, time: 1.222, data: 0.003) D_A: 0.234 G_A: 0.286 cycle_A: 0.217 idt_A: 0.065 D_B: 0.220 G_B: 0.297 cycle_B: 0.172 idt_B: 0.100 \n",
            "(epoch: 163, iters: 128, time: 1.658, data: 0.001) D_A: 0.258 G_A: 0.281 cycle_A: 0.228 idt_A: 0.077 D_B: 0.248 G_B: 0.231 cycle_B: 0.167 idt_B: 0.109 \n",
            "End of epoch 163 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 52, time: 1.224, data: 0.003) D_A: 0.278 G_A: 0.229 cycle_A: 0.337 idt_A: 0.082 D_B: 0.265 G_B: 0.226 cycle_B: 0.194 idt_B: 0.169 \n",
            "(epoch: 164, iters: 152, time: 1.219, data: 0.004) D_A: 0.255 G_A: 0.363 cycle_A: 0.165 idt_A: 0.060 D_B: 0.213 G_B: 0.357 cycle_B: 0.190 idt_B: 0.072 \n",
            "End of epoch 164 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 76, time: 1.219, data: 0.003) D_A: 0.261 G_A: 0.240 cycle_A: 0.296 idt_A: 0.057 D_B: 0.254 G_B: 0.223 cycle_B: 0.126 idt_B: 0.122 \n",
            "(epoch: 165, iters: 176, time: 0.799, data: 0.003) D_A: 0.225 G_A: 0.239 cycle_A: 0.147 idt_A: 0.106 D_B: 0.212 G_B: 0.376 cycle_B: 0.205 idt_B: 0.059 \n",
            "saving the model at the end of epoch 165, iters 8800\n",
            "End of epoch 165 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 1.224, data: 3.023) D_A: 0.253 G_A: 0.222 cycle_A: 0.187 idt_A: 0.087 D_B: 0.239 G_B: 0.304 cycle_B: 0.211 idt_B: 0.071 \n",
            "End of epoch 166 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 24, time: 1.219, data: 0.011) D_A: 0.230 G_A: 0.268 cycle_A: 0.211 idt_A: 0.078 D_B: 0.245 G_B: 0.336 cycle_B: 0.145 idt_B: 0.138 \n",
            "(epoch: 167, iters: 124, time: 1.220, data: 0.001) D_A: 0.256 G_A: 0.321 cycle_A: 0.126 idt_A: 0.063 D_B: 0.248 G_B: 0.234 cycle_B: 0.131 idt_B: 0.050 \n",
            "End of epoch 167 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 48, time: 1.655, data: 0.003) D_A: 0.218 G_A: 0.279 cycle_A: 0.220 idt_A: 0.078 D_B: 0.220 G_B: 0.368 cycle_B: 0.149 idt_B: 0.155 \n",
            "(epoch: 168, iters: 148, time: 1.222, data: 0.006) D_A: 0.241 G_A: 0.173 cycle_A: 0.352 idt_A: 0.092 D_B: 0.265 G_B: 0.265 cycle_B: 0.218 idt_B: 0.131 \n",
            "End of epoch 168 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 72, time: 1.224, data: 0.003) D_A: 0.254 G_A: 0.211 cycle_A: 0.175 idt_A: 0.057 D_B: 0.236 G_B: 0.353 cycle_B: 0.114 idt_B: 0.109 \n",
            "(epoch: 169, iters: 172, time: 1.222, data: 0.003) D_A: 0.245 G_A: 0.206 cycle_A: 0.249 idt_A: 0.092 D_B: 0.288 G_B: 0.351 cycle_B: 0.183 idt_B: 0.130 \n",
            "End of epoch 169 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 96, time: 1.638, data: 0.003) D_A: 0.224 G_A: 0.339 cycle_A: 0.140 idt_A: 0.087 D_B: 0.229 G_B: 0.253 cycle_B: 0.192 idt_B: 0.056 \n",
            "saving the model at the end of epoch 170, iters 9680\n",
            "End of epoch 170 / 200 \t Time Taken: 206 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 20, time: 1.220, data: 0.006) D_A: 0.232 G_A: 0.316 cycle_A: 0.152 idt_A: 0.162 D_B: 0.245 G_B: 0.275 cycle_B: 0.299 idt_B: 0.069 \n",
            "(epoch: 171, iters: 120, time: 1.221, data: 0.001) D_A: 0.279 G_A: 0.258 cycle_A: 0.146 idt_A: 0.064 D_B: 0.244 G_B: 0.273 cycle_B: 0.137 idt_B: 0.085 \n",
            "End of epoch 171 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 44, time: 1.221, data: 0.002) D_A: 0.255 G_A: 0.179 cycle_A: 0.166 idt_A: 0.143 D_B: 0.225 G_B: 0.361 cycle_B: 0.294 idt_B: 0.093 \n",
            "(epoch: 172, iters: 144, time: 1.627, data: 0.003) D_A: 0.249 G_A: 0.365 cycle_A: 0.166 idt_A: 0.072 D_B: 0.224 G_B: 0.259 cycle_B: 0.137 idt_B: 0.085 \n",
            "saving the latest model (epoch 172, total_iters 10000)\n",
            "End of epoch 172 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 168, time: 1.219, data: 0.004) D_A: 0.185 G_A: 0.384 cycle_A: 0.169 idt_A: 0.075 D_B: 0.216 G_B: 0.280 cycle_B: 0.140 idt_B: 0.091 \n",
            "End of epoch 173 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 92, time: 1.225, data: 0.002) D_A: 0.237 G_A: 0.296 cycle_A: 0.186 idt_A: 0.111 D_B: 0.241 G_B: 0.232 cycle_B: 0.188 idt_B: 0.082 \n",
            "End of epoch 174 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 16, time: 1.640, data: 0.003) D_A: 0.239 G_A: 0.270 cycle_A: 0.199 idt_A: 0.096 D_B: 0.223 G_B: 0.249 cycle_B: 0.177 idt_B: 0.101 \n",
            "(epoch: 175, iters: 116, time: 1.219, data: 0.003) D_A: 0.222 G_A: 0.326 cycle_A: 0.182 idt_A: 0.058 D_B: 0.230 G_B: 0.242 cycle_B: 0.128 idt_B: 0.062 \n",
            "saving the model at the end of epoch 175, iters 10560\n",
            "End of epoch 175 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 40, time: 1.221, data: 0.003) D_A: 0.307 G_A: 0.250 cycle_A: 0.164 idt_A: 0.077 D_B: 0.212 G_B: 0.275 cycle_B: 0.151 idt_B: 0.085 \n",
            "(epoch: 176, iters: 140, time: 1.219, data: 0.003) D_A: 0.219 G_A: 0.303 cycle_A: 0.150 idt_A: 0.091 D_B: 0.227 G_B: 0.232 cycle_B: 0.174 idt_B: 0.080 \n",
            "End of epoch 176 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 64, time: 1.658, data: 0.005) D_A: 0.240 G_A: 0.269 cycle_A: 0.281 idt_A: 0.064 D_B: 0.222 G_B: 0.277 cycle_B: 0.114 idt_B: 0.150 \n",
            "(epoch: 177, iters: 164, time: 1.224, data: 0.005) D_A: 0.267 G_A: 0.229 cycle_A: 0.153 idt_A: 0.062 D_B: 0.275 G_B: 0.318 cycle_B: 0.122 idt_B: 0.072 \n",
            "End of epoch 177 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 88, time: 1.217, data: 0.003) D_A: 0.213 G_A: 0.266 cycle_A: 0.218 idt_A: 0.052 D_B: 0.281 G_B: 0.255 cycle_B: 0.114 idt_B: 0.104 \n",
            "End of epoch 178 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 12, time: 1.220, data: 0.003) D_A: 0.219 G_A: 0.327 cycle_A: 0.189 idt_A: 0.104 D_B: 0.236 G_B: 0.296 cycle_B: 0.198 idt_B: 0.079 \n",
            "(epoch: 179, iters: 112, time: 1.656, data: 0.003) D_A: 0.198 G_A: 0.323 cycle_A: 0.164 idt_A: 0.065 D_B: 0.241 G_B: 0.321 cycle_B: 0.138 idt_B: 0.079 \n",
            "End of epoch 179 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 36, time: 1.224, data: 0.006) D_A: 0.233 G_A: 0.230 cycle_A: 0.170 idt_A: 0.063 D_B: 0.236 G_B: 0.272 cycle_B: 0.131 idt_B: 0.107 \n",
            "(epoch: 180, iters: 136, time: 1.220, data: 0.004) D_A: 0.289 G_A: 0.315 cycle_A: 0.135 idt_A: 0.071 D_B: 0.255 G_B: 0.228 cycle_B: 0.144 idt_B: 0.058 \n",
            "saving the model at the end of epoch 180, iters 11440\n",
            "End of epoch 180 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 60, time: 1.220, data: 0.003) D_A: 0.217 G_A: 0.273 cycle_A: 0.175 idt_A: 0.075 D_B: 0.262 G_B: 0.426 cycle_B: 0.145 idt_B: 0.108 \n",
            "(epoch: 181, iters: 160, time: 1.652, data: 0.003) D_A: 0.239 G_A: 0.249 cycle_A: 0.211 idt_A: 0.069 D_B: 0.265 G_B: 0.269 cycle_B: 0.119 idt_B: 0.104 \n",
            "End of epoch 181 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 84, time: 1.221, data: 0.003) D_A: 0.241 G_A: 0.346 cycle_A: 0.183 idt_A: 0.092 D_B: 0.242 G_B: 0.235 cycle_B: 0.200 idt_B: 0.092 \n",
            "End of epoch 182 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 8, time: 1.223, data: 0.003) D_A: 0.229 G_A: 0.337 cycle_A: 0.237 idt_A: 0.076 D_B: 0.268 G_B: 0.277 cycle_B: 0.203 idt_B: 0.123 \n",
            "(epoch: 183, iters: 108, time: 1.221, data: 0.001) D_A: 0.209 G_A: 0.323 cycle_A: 0.137 idt_A: 0.061 D_B: 0.255 G_B: 0.285 cycle_B: 0.135 idt_B: 0.072 \n",
            "End of epoch 183 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 32, time: 1.691, data: 0.003) D_A: 0.241 G_A: 0.260 cycle_A: 0.291 idt_A: 0.075 D_B: 0.241 G_B: 0.299 cycle_B: 0.166 idt_B: 0.130 \n",
            "(epoch: 184, iters: 132, time: 1.222, data: 0.003) D_A: 0.256 G_A: 0.378 cycle_A: 0.137 idt_A: 0.059 D_B: 0.256 G_B: 0.276 cycle_B: 0.125 idt_B: 0.095 \n",
            "End of epoch 184 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 56, time: 1.218, data: 0.003) D_A: 0.283 G_A: 0.345 cycle_A: 0.215 idt_A: 0.060 D_B: 0.266 G_B: 0.262 cycle_B: 0.140 idt_B: 0.070 \n",
            "(epoch: 185, iters: 156, time: 1.221, data: 0.003) D_A: 0.254 G_A: 0.261 cycle_A: 0.124 idt_A: 0.059 D_B: 0.215 G_B: 0.276 cycle_B: 0.143 idt_B: 0.057 \n",
            "saving the model at the end of epoch 185, iters 12320\n",
            "End of epoch 185 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 80, time: 1.685, data: 0.003) D_A: 0.244 G_A: 0.255 cycle_A: 0.319 idt_A: 0.057 D_B: 0.267 G_B: 0.331 cycle_B: 0.126 idt_B: 0.159 \n",
            "End of epoch 186 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 4, time: 1.153, data: 0.004) D_A: 0.233 G_A: 0.303 cycle_A: 0.215 idt_A: 0.083 D_B: 0.235 G_B: 0.270 cycle_B: 0.162 idt_B: 0.083 \n",
            "(epoch: 187, iters: 104, time: 1.218, data: 0.004) D_A: 0.252 G_A: 0.225 cycle_A: 0.204 idt_A: 0.114 D_B: 0.258 G_B: 0.323 cycle_B: 0.152 idt_B: 0.109 \n",
            "End of epoch 187 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 28, time: 1.222, data: 0.003) D_A: 0.239 G_A: 0.277 cycle_A: 0.118 idt_A: 0.077 D_B: 0.207 G_B: 0.349 cycle_B: 0.152 idt_B: 0.055 \n",
            "(epoch: 188, iters: 128, time: 1.672, data: 0.002) D_A: 0.242 G_A: 0.290 cycle_A: 0.129 idt_A: 0.069 D_B: 0.249 G_B: 0.257 cycle_B: 0.161 idt_B: 0.090 \n",
            "End of epoch 188 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 52, time: 1.219, data: 0.004) D_A: 0.254 G_A: 0.276 cycle_A: 0.125 idt_A: 0.071 D_B: 0.249 G_B: 0.207 cycle_B: 0.135 idt_B: 0.076 \n",
            "(epoch: 189, iters: 152, time: 1.221, data: 0.003) D_A: 0.243 G_A: 0.273 cycle_A: 0.189 idt_A: 0.067 D_B: 0.250 G_B: 0.373 cycle_B: 0.129 idt_B: 0.122 \n",
            "End of epoch 189 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 76, time: 1.224, data: 0.003) D_A: 0.239 G_A: 0.197 cycle_A: 0.204 idt_A: 0.060 D_B: 0.247 G_B: 0.323 cycle_B: 0.119 idt_B: 0.092 \n",
            "(epoch: 190, iters: 176, time: 0.809, data: 0.003) D_A: 0.229 G_A: 0.256 cycle_A: 0.097 idt_A: 0.080 D_B: 0.275 G_B: 0.330 cycle_B: 0.117 idt_B: 0.042 \n",
            "saving the model at the end of epoch 190, iters 13200\n",
            "End of epoch 190 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 1.222, data: 0.573) D_A: 0.235 G_A: 0.386 cycle_A: 0.119 idt_A: 0.068 D_B: 0.218 G_B: 0.310 cycle_B: 0.155 idt_B: 0.056 \n",
            "End of epoch 191 / 200 \t Time Taken: 201 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 24, time: 1.225, data: 0.003) D_A: 0.228 G_A: 0.284 cycle_A: 0.160 idt_A: 0.064 D_B: 0.205 G_B: 0.260 cycle_B: 0.148 idt_B: 0.078 \n",
            "(epoch: 192, iters: 124, time: 1.218, data: 0.003) D_A: 0.271 G_A: 0.239 cycle_A: 0.168 idt_A: 0.105 D_B: 0.269 G_B: 0.243 cycle_B: 0.176 idt_B: 0.063 \n",
            "End of epoch 192 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 48, time: 1.661, data: 0.003) D_A: 0.247 G_A: 0.299 cycle_A: 0.255 idt_A: 0.062 D_B: 0.223 G_B: 0.226 cycle_B: 0.128 idt_B: 0.132 \n",
            "(epoch: 193, iters: 148, time: 1.222, data: 0.003) D_A: 0.215 G_A: 0.213 cycle_A: 0.175 idt_A: 0.061 D_B: 0.228 G_B: 0.331 cycle_B: 0.123 idt_B: 0.095 \n",
            "End of epoch 193 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 72, time: 1.222, data: 0.002) D_A: 0.274 G_A: 0.285 cycle_A: 0.153 idt_A: 0.064 D_B: 0.225 G_B: 0.204 cycle_B: 0.115 idt_B: 0.088 \n",
            "(epoch: 194, iters: 172, time: 1.218, data: 0.002) D_A: 0.266 G_A: 0.249 cycle_A: 0.144 idt_A: 0.075 D_B: 0.286 G_B: 0.242 cycle_B: 0.139 idt_B: 0.074 \n",
            "End of epoch 194 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 96, time: 1.691, data: 0.002) D_A: 0.243 G_A: 0.302 cycle_A: 0.173 idt_A: 0.073 D_B: 0.263 G_B: 0.238 cycle_B: 0.156 idt_B: 0.085 \n",
            "saving the model at the end of epoch 195, iters 14080\n",
            "End of epoch 195 / 200 \t Time Taken: 204 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 20, time: 1.219, data: 0.004) D_A: 0.192 G_A: 0.351 cycle_A: 0.119 idt_A: 0.071 D_B: 0.186 G_B: 0.383 cycle_B: 0.146 idt_B: 0.067 \n",
            "(epoch: 196, iters: 120, time: 1.220, data: 0.007) D_A: 0.267 G_A: 0.201 cycle_A: 0.113 idt_A: 0.071 D_B: 0.267 G_B: 0.302 cycle_B: 0.131 idt_B: 0.067 \n",
            "End of epoch 196 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 44, time: 1.218, data: 0.003) D_A: 0.300 G_A: 0.307 cycle_A: 0.148 idt_A: 0.058 D_B: 0.216 G_B: 0.230 cycle_B: 0.108 idt_B: 0.065 \n",
            "(epoch: 197, iters: 144, time: 1.661, data: 0.002) D_A: 0.215 G_A: 0.341 cycle_A: 0.306 idt_A: 0.068 D_B: 0.178 G_B: 0.313 cycle_B: 0.102 idt_B: 0.162 \n",
            "End of epoch 197 / 200 \t Time Taken: 202 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 68, time: 1.218, data: 0.002) D_A: 0.207 G_A: 0.232 cycle_A: 0.157 idt_A: 0.070 D_B: 0.199 G_B: 0.310 cycle_B: 0.136 idt_B: 0.101 \n",
            "(epoch: 198, iters: 168, time: 1.218, data: 0.003) D_A: 0.191 G_A: 0.353 cycle_A: 0.175 idt_A: 0.067 D_B: 0.208 G_B: 0.287 cycle_B: 0.113 idt_B: 0.084 \n",
            "End of epoch 198 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 92, time: 1.221, data: 0.002) D_A: 0.240 G_A: 0.296 cycle_A: 0.252 idt_A: 0.059 D_B: 0.229 G_B: 0.301 cycle_B: 0.109 idt_B: 0.146 \n",
            "End of epoch 199 / 200 \t Time Taken: 200 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 16, time: 1.714, data: 0.003) D_A: 0.199 G_A: 0.374 cycle_A: 0.120 idt_A: 0.058 D_B: 0.211 G_B: 0.261 cycle_B: 0.123 idt_B: 0.057 \n",
            "(epoch: 200, iters: 116, time: 1.221, data: 0.003) D_A: 0.228 G_A: 0.290 cycle_A: 0.120 idt_A: 0.056 D_B: 0.255 G_B: 0.310 cycle_B: 0.104 idt_B: 0.055 \n",
            "saving the model at the end of epoch 200, iters 14960\n",
            "End of epoch 200 / 200 \t Time Taken: 203 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWu93JDQDCry",
        "outputId": "a8895ece-8a87-40ef-b871-6c4c70eafd5c"
      },
      "source": [
        "!pip install POT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting POT\n",
            "  Downloading POT-0.7.0-cp37-cp37m-manylinux2010_x86_64.whl (430 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 133 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 194 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 266 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 317 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 327 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 378 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 389 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 399 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from POT) (1.19.5)\n",
            "Requirement already satisfied: cython>=0.23 in /usr/local/lib/python3.7/dist-packages (from POT) (0.29.24)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from POT) (1.4.1)\n",
            "Installing collected packages: POT\n",
            "Successfully installed POT-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SIg1e_4BZoK"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import timeit\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import ot\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.models as models\n",
        "import pdb\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy.stats import entropy\n",
        "from numpy.linalg import norm\n",
        "from scipy import linalg\n",
        "\n",
        "\n",
        "def giveName(iter):  # 7 digit name.\n",
        "    ans = str(iter)\n",
        "    return ans.zfill(7)\n",
        "\n",
        "\n",
        "def make_dataset(dataset, dataroot, imageSize):\n",
        "    \"\"\"\n",
        "    :param dataset: must be in 'cifar10 | lsun | imagenet | folder | lfw | fake'\n",
        "    :return: pytorch dataset for DataLoader to utilize\n",
        "    \"\"\"\n",
        "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
        "        # folder dataset\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                       transforms.Resize(imageSize),\n",
        "                                       transforms.CenterCrop(imageSize),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                   ]))\n",
        "    elif dataset == 'lsun':\n",
        "        dataset = dset.LSUN(db_path=dataroot, classes=['bedroom_train'],\n",
        "                            transform=transforms.Compose([\n",
        "                                transforms.Resize(imageSize),\n",
        "                                transforms.CenterCrop(imageSize),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(\n",
        "                                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                            ]))\n",
        "    elif dataset == 'cifar10':\n",
        "        dataset = dset.CIFAR10(root=dataroot, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.Resize(imageSize),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(\n",
        "                                       (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                               ]))\n",
        "    elif dataset == 'celeba':\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                       transforms.CenterCrop(138),\n",
        "                                       transforms.Resize(imageSize),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                   ]))\n",
        "    else:\n",
        "        raise Exception('--dataset must be in cifar10 | lsun | imagenet | folder | lfw | fake')\n",
        "    assert dataset\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def sampleFake(netG, nz, sampleSize, batchSize, saveFolder):\n",
        "    print('sampling fake images ...')\n",
        "    saveFolder = saveFolder + '0/'\n",
        "\n",
        "    try:\n",
        "        os.makedirs(saveFolder)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "    noise = torch.FloatTensor(batchSize, nz, 1, 1).cuda()\n",
        "    iter = 0\n",
        "    for i in range(0, 1 + sampleSize // batchSize):\n",
        "        noise.data.normal_(0, 1)\n",
        "        fake = netG(noise)\n",
        "        for j in range(0, len(fake.data)):\n",
        "            if iter < sampleSize:\n",
        "                vutils.save_image(fake.data[j].mul(0.5).add(\n",
        "                    0.5), saveFolder + giveName(iter) + \".png\")\n",
        "            iter += 1\n",
        "            if iter >= sampleSize:\n",
        "                break\n",
        "\n",
        "\n",
        "def sampleTrue(dataset, imageSize, dataroot, sampleSize, batchSize, saveFolder, workers=4):\n",
        "    print('sampling real images ...')\n",
        "    saveFolder = saveFolder + '0/'\n",
        "\n",
        "    dataset = make_dataset(dataset, dataroot, imageSize)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, shuffle=True, batch_size=batchSize, num_workers=int(workers))\n",
        "\n",
        "    if not os.path.exists(saveFolder):\n",
        "        try:\n",
        "            os.makedirs(saveFolder)\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "    iter = 0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        img, _ = data\n",
        "        for j in range(0, len(img)):\n",
        "\n",
        "            vutils.save_image(img[j].mul(0.5).add(\n",
        "                0.5), saveFolder + giveName(iter) + \".png\")\n",
        "            iter += 1\n",
        "            if iter >= sampleSize:\n",
        "                break\n",
        "        if iter >= sampleSize:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "class ConvNetFeatureSaver(object):\n",
        "    def __init__(self, model='resnet34', workers=4, batchSize=64):\n",
        "        '''\n",
        "        model: inception_v3, vgg13, vgg16, vgg19, resnet18, resnet34,\n",
        "               resnet50, resnet101, or resnet152\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.batch_size = batchSize\n",
        "        self.workers = workers\n",
        "        if self.model.find('vgg') >= 0:\n",
        "            self.vgg = getattr(models, model)(pretrained=True).cuda().eval()\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                                     (0.229, 0.224, 0.225)),\n",
        "            ])\n",
        "        elif self.model.find('resnet') >= 0:\n",
        "            resnet = getattr(models, model)(pretrained=True)\n",
        "            resnet.cuda().eval()\n",
        "            resnet_feature = nn.Sequential(resnet.conv1, resnet.bn1,\n",
        "                                           resnet.relu,\n",
        "                                           resnet.maxpool, resnet.layer1,\n",
        "                                           resnet.layer2, resnet.layer3,\n",
        "                                           resnet.layer4).cuda().eval()\n",
        "            self.resnet = resnet\n",
        "            self.resnet_feature = resnet_feature\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                                     (0.229, 0.224, 0.225)),\n",
        "            ])\n",
        "        elif self.model == 'inception' or self.model == 'inception_v3':\n",
        "            inception = models.inception_v3(\n",
        "                pretrained=True, transform_input=False).cuda().eval()\n",
        "            inception_feature = nn.Sequential(inception.Conv2d_1a_3x3,\n",
        "                                              inception.Conv2d_2a_3x3,\n",
        "                                              inception.Conv2d_2b_3x3,\n",
        "                                              nn.MaxPool2d(3, 2),\n",
        "                                              inception.Conv2d_3b_1x1,\n",
        "                                              inception.Conv2d_4a_3x3,\n",
        "                                              nn.MaxPool2d(3, 2),\n",
        "                                              inception.Mixed_5b,\n",
        "                                              inception.Mixed_5c,\n",
        "                                              inception.Mixed_5d,\n",
        "                                              inception.Mixed_6a,\n",
        "                                              inception.Mixed_6b,\n",
        "                                              inception.Mixed_6c,\n",
        "                                              inception.Mixed_6d,\n",
        "                                              inception.Mixed_7a,\n",
        "                                              inception.Mixed_7b,\n",
        "                                              inception.Mixed_7c,\n",
        "                                              ).cuda().eval()\n",
        "            self.inception = inception\n",
        "            self.inception_feature = inception_feature\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(299),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ])\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def save(self, imgFolder, save2disk=False):\n",
        "        dataset = dset.ImageFolder(root=imgFolder, transform=self.trans)\n",
        "        dataloader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=self.batch_size, num_workers=self.workers)\n",
        "        print('extracting features...')\n",
        "        feature_pixl, feature_conv, feature_smax, feature_logit = [], [], [], []\n",
        "        for img, _ in tqdm(dataloader):\n",
        "            with torch.no_grad():\n",
        "                input = img.cuda()\n",
        "                if self.model == 'vgg' or self.model == 'vgg16':\n",
        "                    fconv = self.vgg.features(input).view(input.size(0), -1)\n",
        "                    flogit = self.vgg.classifier(fconv)\n",
        "                    # flogit = self.vgg.logitifier(fconv)\n",
        "                elif self.model.find('resnet') >= 0:\n",
        "                    fconv = self.resnet_feature(\n",
        "                        input).mean(3).mean(2).squeeze()\n",
        "                    flogit = self.resnet.fc(fconv)\n",
        "                elif self.model == 'inception' or self.model == 'inception_v3':\n",
        "                    fconv = self.inception_feature(\n",
        "                        input).mean(3).mean(2).squeeze()\n",
        "                    flogit = self.inception.fc(fconv)\n",
        "                else:\n",
        "                    raise NotImplementedError\n",
        "                fsmax = F.softmax(flogit)\n",
        "                feature_pixl.append(img)\n",
        "                feature_conv.append(fconv.data.cpu())\n",
        "                feature_logit.append(flogit.data.cpu())\n",
        "                feature_smax.append(fsmax.data.cpu())\n",
        "\n",
        "        feature_pixl = torch.cat(feature_pixl, 0).to('cpu')\n",
        "        feature_conv = torch.cat(feature_conv, 0).to('cpu')\n",
        "        feature_logit = torch.cat(feature_logit, 0).to('cpu')\n",
        "        feature_smax = torch.cat(feature_smax, 0).to('cpu')\n",
        "\n",
        "        if save2disk:\n",
        "            torch.save(feature_conv, os.path.join(\n",
        "                imgFolder, 'feature_pixl.pth'))\n",
        "            torch.save(feature_conv, os.path.join(\n",
        "                imgFolder, 'feature_conv.pth'))\n",
        "            torch.save(feature_logit, os.path.join(\n",
        "                imgFolder, 'feature_logit.pth'))\n",
        "            torch.save(feature_smax, os.path.join(\n",
        "                imgFolder, 'feature_smax.pth'))\n",
        "\n",
        "        return feature_pixl, feature_conv, feature_logit, feature_smax\n",
        "\n",
        "\n",
        "def distance(X, Y, sqrt):\n",
        "    nX = X.size(0)\n",
        "    nY = Y.size(0)\n",
        "    X = X.view(nX,-1)\n",
        "    X2 = (X*X).sum(1).resize_(nX,1)\n",
        "    Y = Y.view(nY,-1)\n",
        "    Y2 = (Y*Y).sum(1).resize_(nY,1)\n",
        "\n",
        "    M = torch.zeros(nX, nY)\n",
        "    M.copy_(X2.expand(nX, nY) + Y2.expand(nY, nX).transpose(0, 1) -\n",
        "            2 * torch.mm(X, Y.transpose(0, 1)))\n",
        "\n",
        "    del X, X2, Y, Y2\n",
        "\n",
        "    if sqrt:\n",
        "        M = ((M + M.abs()) / 2).sqrt()\n",
        "\n",
        "    return M\n",
        "\n",
        "\n",
        "def wasserstein(M, sqrt):\n",
        "    if sqrt:\n",
        "        M = M.abs().sqrt()\n",
        "    emd = ot.emd2([], [], M.numpy())\n",
        "\n",
        "    return emd\n",
        "\n",
        "\n",
        "class Score_knn:\n",
        "    acc = 0\n",
        "    acc_real = 0\n",
        "    acc_fake = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    tn = 0\n",
        "\n",
        "\n",
        "def knn(Mxx, Mxy, Myy, k, sqrt):\n",
        "    n0 = Mxx.size(0)\n",
        "    n1 = Myy.size(0)\n",
        "    label = torch.cat((torch.ones(n0), torch.zeros(n1)))\n",
        "    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat(\n",
        "        (Mxy.transpose(0, 1), Myy), 1)), 0)\n",
        "    if sqrt:\n",
        "        M = M.abs().sqrt()\n",
        "    INFINITY = float('inf')\n",
        "    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1))\n",
        "                ).topk(k, 0, False)\n",
        "\n",
        "    count = torch.zeros(n0 + n1)\n",
        "    for i in range(0, k):\n",
        "        count = count + label.index_select(0, idx[i])\n",
        "    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1)).float()\n",
        "\n",
        "    s = Score_knn()\n",
        "    s.tp = (pred * label).sum()\n",
        "    s.fp = (pred * (1 - label)).sum()\n",
        "    s.fn = ((1 - pred) * label).sum()\n",
        "    s.tn = ((1 - pred) * (1 - label)).sum()\n",
        "    s.precision = s.tp / (s.tp + s.fp + 1e-10)\n",
        "    s.recall = s.tp / (s.tp + s.fn + 1e-10)\n",
        "    s.acc_real = s.tp / (s.tp + s.fn)\n",
        "    s.acc_fake = s.tn / (s.tn + s.fp)\n",
        "    s.acc = torch.eq(label, pred).float().mean()\n",
        "    s.k = k\n",
        "    print(\"Prcision:\", s.precision, \"Recall:\", s.recall, \"Accuracy:\", s.acc)\n",
        "    print(\"\\n\")\n",
        "    return s\n",
        "\n",
        "\n",
        "def mmd(Mxx, Mxy, Myy, sigma):\n",
        "    scale = Mxx.mean()\n",
        "    Mxx = torch.exp(-Mxx / (scale * 2 * sigma * sigma))\n",
        "    Mxy = torch.exp(-Mxy / (scale * 2 * sigma * sigma))\n",
        "    Myy = torch.exp(-Myy / (scale * 2 * sigma * sigma))\n",
        "    mmd = math.sqrt(Mxx.mean() + Myy.mean() - 2 * Mxy.mean())\n",
        "    print(\"\\nMMD Score:\",mmd)\n",
        "    return mmd\n",
        "\n",
        "\n",
        "def entropy_score(X, Y, epsilons):\n",
        "    Mxy = distance(X, Y, False)\n",
        "    scores = []\n",
        "    for epsilon in epsilons:\n",
        "        scores.append(ent(Mxy.t(), epsilon))\n",
        "    print(\"\\nEntropy Score:\",scores)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def ent(M, epsilon):\n",
        "    n0 = M.size(0)\n",
        "    n1 = M.size(1)\n",
        "    neighbors = M.lt(epsilon).float()\n",
        "    sums = neighbors.sum(0).repeat(n0, 1)\n",
        "    sums[sums.eq(0)] = 1\n",
        "    neighbors = neighbors.div(sums)\n",
        "    probs = neighbors.sum(1) / n1\n",
        "    rem = 1 - probs.sum()\n",
        "    if rem < 0:\n",
        "        rem = 0\n",
        "    probs = torch.cat((probs, rem*torch.ones(1)), 0)\n",
        "    e = {}\n",
        "    e['probs'] = probs\n",
        "    probs = probs[probs.gt(0)]\n",
        "    e['ent'] = -probs.mul(probs.log()).sum()\n",
        "\n",
        "    return e\n",
        "\n",
        "\n",
        "\n",
        "eps = 1e-20\n",
        "def inception_score(X):\n",
        "    kl = X * ((X+eps).log()-(X.mean(0)+eps).log().expand_as(X))\n",
        "    score = np.exp(kl.sum(1).mean())\n",
        "    print(\"\\nInception Score:\", score)\n",
        "    return score\n",
        "\n",
        "def mode_score(X, Y):\n",
        "    kl1 = X * ((X+eps).log()-(X.mean(0)+eps).log().expand_as(X))\n",
        "    kl2 = X.mean(0) * ((X.mean(0)+eps).log()-(Y.mean(0)+eps).log())\n",
        "    score = np.exp(kl1.sum(1).mean() - kl2.sum())\n",
        "    print(\"\\n Mode Score:\", score)\n",
        "    return score\n",
        "\n",
        "\n",
        "def fid(X, Y):\n",
        "    m = X.mean(0)\n",
        "    m_w = Y.mean(0)\n",
        "    X_np = X.numpy()\n",
        "    Y_np = Y.numpy()\n",
        "\n",
        "    C = np.cov(X_np.transpose())\n",
        "    C_w = np.cov(Y_np.transpose())\n",
        "    C_C_w_sqrt = linalg.sqrtm(C.dot(C_w), True).real\n",
        "\n",
        "    score = m.dot(m) + m_w.dot(m_w) - 2 * m_w.dot(m) + \\\n",
        "        np.trace(C + C_w - 2 * C_C_w_sqrt)\n",
        "    print(\"\\nFID:\", np.sqrt(score))\n",
        "    return np.sqrt(score)\n",
        "\n",
        "\n",
        "class Score:\n",
        "    emd = 0\n",
        "    mmd = 0\n",
        "    knn = None\n",
        "\n",
        "\n",
        "def compute_score(real, fake, k=1, sigma=1, sqrt=True):\n",
        "\n",
        "    Mxx = distance(real, real, False)\n",
        "    Mxy = distance(real, fake, False)\n",
        "    Myy = distance(fake, fake, False)\n",
        "\n",
        "    s = Score()\n",
        "    s.emd = wasserstein(Mxy, sqrt)\n",
        "    s.mmd = mmd(Mxx, Mxy, Myy, sigma)\n",
        "    s.knn = knn(Mxx, Mxy, Myy, k, sqrt)\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def compute_score_raw(batchSize, conv_model='resnet34', workers=4):\n",
        "\n",
        "   # sampleTrue(dataset, imageSize, dataroot, sampleSize, batchSize,\n",
        "              # saveFolder_r, workers=workers)\n",
        "   # sampleFake(netG, nz, sampleSize, batchSize, saveFolder_f, )\n",
        "    saveFolder_f = '/content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/web/';\n",
        "    saveFolder_r = '/content/drive/My Drive/LOP_DATASET/train/'; \n",
        "    convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,batchSize=batchSize, workers=workers)\n",
        "    feature_r = convnet_feature_saver.save(saveFolder_r)\n",
        "    feature_f = convnet_feature_saver.save(saveFolder_f)\n",
        "\n",
        "    # 4 feature spaces and 7 scores + incep + modescore + fid\n",
        "    score = np.zeros(4 * 7 + 3)\n",
        "    for i in range(0, 4):\n",
        "        print('compute score in space: ' + str(i))\n",
        "        Mxx = distance(feature_r[i], feature_r[i], False)\n",
        "        Mxy = distance(feature_r[i], feature_f[i], False)\n",
        "        Myy = distance(feature_f[i], feature_f[i], False)\n",
        "\n",
        "        score[i * 7] = wasserstein(Mxy, True)\n",
        "        score[i * 7 + 1] = mmd(Mxx, Mxy, Myy, 1)\n",
        "        tmp = knn(Mxx, Mxy, Myy, 1, False)\n",
        "        score[(i * 7 + 2):(i * 7 + 7)] = \\\n",
        "            tmp.acc, tmp.acc_real, tmp.acc_fake, tmp.precision, tmp.recall\n",
        "\n",
        "    score[28] = inception_score(feature_f[3])\n",
        "    score[29] = mode_score(feature_r[3], feature_f[3])\n",
        "    score[30] = fid(feature_r[3], feature_f[3])\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeBLi9UDs02"
      },
      "source": [
        "outf = '/content/drive/My Drive/CGAN_LOP/metrics'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707,
          "referenced_widgets": [
            "175bfc9a17d8447d9e6dc010294581e1",
            "4c8883daec7b473696802afd28dfb339",
            "0f1e70f6943d4491961531f8a4b4cb85",
            "57c9dab874274d9592fadb3c7a593a1f",
            "f30705167937413683232dd01b8f0432",
            "030a5b6636524a73bc3da10192cd8978",
            "e6a6895f98c946bdbe2a3d8435aabee7",
            "1b1062e393e744eca4a4cf0d0ba44068",
            "35e103c52c5b4fda8cc8572d338cb166",
            "073d9abb0c784f158e762f3bfa7e17f2",
            "97b61f905bf8408994d3f13d0b06cfca"
          ]
        },
        "id": "xMqH5iqVDIrG",
        "outputId": "7e3eba8b-6757-4d96-cc43-dd1012d6079b"
      },
      "source": [
        "s = compute_score_raw(16, conv_model='inception_v3', workers=int(2))\n",
        "score_tr = s\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "175bfc9a17d8447d9e6dc010294581e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/104M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:214: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 18/18 [00:52<00:00,  2.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45/45 [02:48<00:00,  3.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute score in space: 0\n",
            "\n",
            "MMD Score: 0.1285418359063929\n",
            "Prcision: tensor(1.) Recall: tensor(0.8842) Accuracy: tensor(0.9669)\n",
            "\n",
            "\n",
            "compute score in space: 1\n",
            "\n",
            "MMD Score: 0.2370267268373537\n",
            "Prcision: tensor(0.7030) Recall: tensor(0.6561) Accuracy: tensor(0.8225)\n",
            "\n",
            "\n",
            "compute score in space: 2\n",
            "\n",
            "MMD Score: 0.2561078212147011\n",
            "Prcision: tensor(0.7050) Recall: tensor(0.6456) Accuracy: tensor(0.8215)\n",
            "\n",
            "\n",
            "compute score in space: 3\n",
            "\n",
            "MMD Score: 0.21190337404640583\n",
            "Prcision: tensor(0.6367) Recall: tensor(0.5719) Accuracy: tensor(0.7844)\n",
            "\n",
            "\n",
            "\n",
            "Inception Score: tensor(1.3632)\n",
            "\n",
            " Mode Score: tensor(1.1983)\n",
            "\n",
            "FID: tensor(0.0783)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gITOPlhGDfw-",
        "outputId": "fa56998a-0696-4af5-d23d-5981911b7233"
      },
      "source": [
        "\n",
        "# save final metric scores of all epoches\n",
        "np.save('%s/score_tr_ep.npy' % outf, score_tr)\n",
        "print('##### training completed :) #####')\n",
        "print('### metric scores output is scored at %s/score_tr_ep.npy ###' % outf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### training completed :) #####\n",
            "### metric scores output is scored at /content/drive/My Drive/CGAN_LOP/metrics/score_tr_ep.npy ###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn7PLNf2ETog",
        "outputId": "5541c932-99a9-4923-bbfc-2f7451995076"
      },
      "source": [
        "new_num_arr = np.load('/content/drive/My Drive/CGAN_LOP/metrics/score_tr_ep.npy') # load\n",
        "print(new_num_arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.75448854e+02 1.28541836e-01 9.66900706e-01 8.84210527e-01\n",
            " 1.00000000e+00 1.00000000e+00 8.84210527e-01 7.86876468e+00\n",
            " 2.37026727e-01 8.22467387e-01 6.56140327e-01 8.89044940e-01\n",
            " 7.03007519e-01 6.56140327e-01 1.60019073e+01 2.56107821e-01\n",
            " 8.21464419e-01 6.45614028e-01 8.91853929e-01 7.04980850e-01\n",
            " 6.45614028e-01 8.28739848e-02 2.11903374e-01 7.84353077e-01\n",
            " 5.71929812e-01 8.69382024e-01 6.36718750e-01 5.71929812e-01\n",
            " 1.36324048e+00 1.19830048e+00 7.83058703e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0NvKb0Ovk_W",
        "outputId": "cf3d3a3e-e9ce-4a19-e3f8-4af426bfc8c6"
      },
      "source": [
        "!python test.py --dataroot '/content/drive/My Drive/CGAN_LOP/testA' --name LOP --model test --no_dropout --checkpoints_dir '/content/drive/My Drive/CGAN_LOP/train_chkpts' --results_dir '/content/drive/My Drive/CGAN_LOP/toCancer' --num_test 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: /content/drive/My Drive/CGAN_LOP/train_chkpts\t[default: ./checkpoints]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/My Drive/CGAN_LOP/testA\t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: LOP                           \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: /content/drive/My Drive/CGAN_LOP/toCancer\t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from /content/drive/My Drive/CGAN_LOP/train_chkpts/LOP/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory /content/drive/My Drive/CGAN_LOP/toCancer/LOP/test_latest\n",
            "processing (0000)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb051.jpg']\n",
            "processing (0005)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb056.jpg']\n",
            "processing (0010)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb064.jpg']\n",
            "processing (0015)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb070.jpg']\n",
            "processing (0020)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb077.jpg']\n",
            "processing (0025)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb085.jpg']\n",
            "processing (0030)-th image... ['/content/drive/My Drive/CGAN_LOP/testA/mdb093.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apU_pfiwIzW5",
        "outputId": "dae5ad9f-32d4-4ee2-8356-a572f1408c0a"
      },
      "source": [
        "!python test.py --dataroot '/content/drive/My Drive/mask/blah' --name MaskFacee --model test --no_dropout --checkpoints_dir '/content/drive/My Drive/train_chkpts' --results_dir '/content/drive/My Drive/resB' --preprocess 'None' --num_test 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: /content/drive/My Drive/train_chkpts\t[default: ./checkpoints]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/My Drive/mask/blah\t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: MaskFacee                     \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 10                            \t[default: 50]\n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: None                          \t[default: resize_and_crop]\n",
            "              results_dir: /content/drive/My Drive/resB  \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from /content/drive/My Drive/train_chkpts/MaskFacee/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory /content/drive/My Drive/resB/MaskFacee/test_latest\n",
            "processing (0000)-th image... ['/content/drive/My Drive/mask/blah/1 (2).jpg']\n",
            "processing (0005)-th image... ['/content/drive/My Drive/mask/blah/janani marr.png']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}